{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import argparse, gzip, cPickle, sys, time, itertools\n",
    "\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy.stats.norm as norm\n",
    "import autograd.scipy.stats.dirichlet as dirichlet\n",
    "from autograd.scipy.misc import logsumexp\n",
    "from autograd.util import flatten_func, flatten\n",
    "from autograd import grad, primitive\n",
    "from autograd.numpy.numpy_grads import unbroadcast\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import mixture\n",
    "\n",
    "from  autograd.scipy.special import gammaln, digamma, gamma\n",
    "from scipy import linalg\n",
    "from scipy import stats, integrate\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import six\n",
    "\n",
    "\n",
    "color_names = [\"maroon\",               \n",
    "               \"gold\",\n",
    "               \"royal blue\"]\n",
    "colors = sns.xkcd_palette(color_names)\n",
    "sns.set_style(\"white\")\n",
    "color_iter = itertools.cycle(colors)\n",
    "\n",
    "def plot_results(ax, X, Y, means, covariances, index, title):    \n",
    "    for i, (mean, covar, color) in enumerate(zip(\n",
    "             means, covariances, color_iter)):\n",
    "        v, w = linalg.eigh(np.diag(np.full([2], covar)))\n",
    "        v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "        u = w[0] / linalg.norm(w[0])      \n",
    "\n",
    "        if not np.any(Y == i):\n",
    "            continue\n",
    "        ax.scatter(X[Y == i, 0], X[Y == i, 1], 2., color=color)\n",
    "\n",
    "        angle = np.arctan(u[1] / u[0])\n",
    "        angle = 180. * angle / np.pi  # convert to degrees\n",
    "        ell = mpl.patches.Ellipse(mean, v[0], v[1], 180. + angle, color=color)\n",
    "        #ell.set_clip_box(splot.bbox)\n",
    "        ell.set_alpha(0.5)\n",
    "        ax.add_artist(ell)\n",
    "        \n",
    "        \n",
    "class Adam(object):\n",
    "    def __init__(self, dparam, b1=0.9, b2=0.999, eps=10**-8,\n",
    "                         decay_rate = 0.9, decay_steps = 100):                    \n",
    "        self.b1 = b1;\n",
    "        self.b2 = b2;\n",
    "        self.eps = eps        \n",
    "        self.m = np.zeros(dparam)\n",
    "        self.v = np.zeros(dparam)\n",
    "        self.i = 0\n",
    "        self.decay_rate = decay_rate\n",
    "        self.decay_steps = decay_steps\n",
    "    \n",
    "    def update(self, gradients, params, learning_rate = 0.1):        \n",
    "        self.i = self.i+1\n",
    "        step_size = learning_rate * self.decay_rate**(self.i/self.decay_steps)        \n",
    "        self.m = (1 - self.b1) * gradients + self.b1 * self.m\n",
    "        self.v = (1 - self.b2) * (gradients**2) + self.b2 * self.v\n",
    "        mhat = self.m / (1 - self.b1**(self.i))\n",
    "        vhat = self.v / (1 - self.b2**(self.i))                        \n",
    "        params = params + step_size*mhat/(np.sqrt(vhat) + self.eps)        \n",
    "        return np.split(params,2)\n",
    "\n",
    "@primitive\n",
    "def softplus(x):\n",
    "    return np.log(1. + np.exp(x))\n",
    "\n",
    "softplus.defvjp(lambda g, ans, vs, gvs, x: unbroadcast(vs, gvs, g * 1./(1. + np.exp(-x))))\n",
    "\n",
    "def jacobian_softplus(x):\n",
    "    return 1./(1. + np.exp(-x))\n",
    "\n",
    "@primitive\n",
    "def gamma_logpdf(x, alpha = 1., beta = 1.):\n",
    "    return  (alpha*np.log(beta) + (alpha - 1)*np.log(x) - x*beta - gammaln(alpha))\n",
    "\n",
    "gamma_logpdf.defvjp(lambda g, ans, vs, gvs, x, alpha=1.0, beta=1.0: unbroadcast(vs, gvs, g * ((alpha-1)/x - beta)))\n",
    "gamma_logpdf.defvjp(lambda g, ans, vs, gvs, x, alpha=1.0, beta=1.0: unbroadcast(vs, gvs,  g * (np.log(beta) + np.log(x) - digamma(alpha))), argnum=1)\n",
    "gamma_logpdf.defvjp(lambda g, ans, vs, gvs, x, alpha=1.0, beta=1.0: unbroadcast(vs, gvs,  g * (alpha/beta - x)), argnum=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression(object):\n",
    "    def __init__(self, data, scale):\n",
    "        self.data = data             \n",
    "        self.scale = scale\n",
    "        self.N = data['x'].shape[0]\n",
    "        self.D = data['x'].shape[1]        \n",
    "    \n",
    "    def p_log_prob(self, idx, z):\n",
    "        x, y = self.data['x'][idx], self.data['y'][idx] \n",
    "        w, tau = z['w'], z['tau']       \n",
    "        log_prior = 0.\n",
    "        log_prior += np.sum(gamma_logpdf(tau, 1e-3, 1e-3) + np.log(jacobian_softplus(z['tau'])))        \n",
    "        #log_prior += np.sum(gamma_logpdf(alpha, 1e-3, 1e-3) + np.log(jacobian_softplus(z['alpha'])))        \n",
    "        log_prior += np.sum(norm.logpdf(w, 0, 1.)) \n",
    "        log_lik = np.sum(norm.logpdf(y, np.matmul(x, w), 1./np.sqrt(tau)))\n",
    "        return self.scale * log_lik + log_prior        \n",
    "         \n",
    "    def q_log_prob(self, means, log_sigmas, z):\n",
    "        q_w = np.sum(norm.logpdf(z, means, np.exp(log_sigmas)))        \n",
    "        return q_w\n",
    "      \n",
    "    def q_log_prob_sep(self, means, log_sigmas, z):\n",
    "        q_w = norm.logpdf(z, means, np.exp(log_sigmas))        \n",
    "        return q_w\n",
    "\n",
    "    def phi_log_prob_sep(self, eps):\n",
    "        phi_w = norm.logpdf(eps, 0., 1.)        \n",
    "        return phi_w\n",
    "\n",
    "    def sample_q(self, means, log_sigmas, d):        \n",
    "        eps = npr.randn(d)        \n",
    "        q_s = np.exp(log_sigmas) * eps + means\n",
    "        return (q_s, eps)\n",
    "        \n",
    "    def grad_params(self, dp_log_prob, eps, log_sigmas):                \n",
    "        grad_means = dp_log_prob\n",
    "        grad_log_sigmas = dp_log_prob*eps*np.exp(log_sigmas) + 1                \n",
    "        return np.concatenate([grad_means, grad_log_sigmas])\n",
    "        \n",
    "    def calc_eps(self, means, log_sigma, z):        \n",
    "        eps  = (z - means)/np.exp(log_sigma)\n",
    "        return eps            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Inference(object):      \n",
    "    def __init__(self, model, params):\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "\n",
    "    def run(self, epochs, batch_size, samples, learning_rate, algorithm = 'SGD', optimizer = 'adam'):\n",
    "        epochs = epochs\n",
    "        batches = self.model.N/batch_size\n",
    "        batch_size = batch_size\n",
    "        samples = samples\n",
    "        learning_rate = learning_rate        \n",
    "        \n",
    "        means, unflatten = flatten(self.params['means'])\n",
    "        log_sigmas, unflatten = flatten(self.params['log_sigmas'])        \n",
    "        D =len(means)\n",
    "\n",
    "        self.F = np.zeros(epochs * batches)\n",
    "        self.time = np.zeros(epochs * batches)\n",
    "        adam = Adam(2*D)\n",
    "        f = 0\n",
    "        \n",
    "        grad_p_log_prob = grad(model.p_log_prob, argnum = 1)\n",
    "        grad_q_log_prob = grad(model.q_log_prob, argnum = 1)\n",
    "        \n",
    "        if algorithm == 'SGD':\n",
    "            for e in range(epochs):\n",
    "                for b in range(batches): \n",
    "                    start = time.clock()\n",
    "                    losses = 0.\n",
    "                    d_elbo = 0.\n",
    "                    idx = np.random.choice(np.arange(self.model.N), batch_size, replace=False)                    \n",
    "                    d_elbo = 0.\n",
    "\n",
    "                    for s in range(samples):\n",
    "                        eps = npr.randn(D)        \n",
    "                        z = np.exp(log_sigmas) * eps + means                                            \n",
    "                        p_log_prob = model.p_log_prob(idx, unflatten(z))                        \n",
    "                        dp_log_prob, _ = flatten(grad_p_log_prob(idx, unflatten(z)))\n",
    "                        g =  model.grad_params(dp_log_prob, eps, log_sigmas)                        \n",
    "                        d_elbo += g\n",
    "                        q_log_prob = model.q_log_prob(means, log_sigmas, z)                                         \n",
    "                        losses +=  (p_log_prob - q_log_prob)                    \n",
    "                    loss = losses/samples\n",
    "                    d_elbo /= samples   \n",
    "                    means_old, log_sigmas_old = means, log_sigmas\n",
    "                    means, log_sigmas = adam.update(d_elbo, np.concatenate([means, log_sigmas]), learning_rate)\n",
    "                    if np.sum(np.isnan(means)) > 0 or np.sum(np.isnan(log_sigmas)) > 0:\n",
    "                        means, log_sigmas = means_old, log_sigmas_old\n",
    "                        learning_rate = learning_rate * .1                        \n",
    "                    self.F[f] =  -loss                \n",
    "\n",
    "                    stop = time.clock()\n",
    "                    self.time[f] = stop - start\n",
    "                    f+=1\n",
    "                if e % 1 == 0:\n",
    "                    pstate = 'Epoch = ' + \"{0:0=3d}\".format(e) + ': Loss = {0:.3f}'.format(self.F[f-1])\n",
    "                    print (pstate, end = '\\r')\n",
    "                    sys.stdout.flush()   \n",
    "                                                                                                              \n",
    "        if algorithm == 'iSGD':\n",
    "            n = 1.  \n",
    "            z_old = [0.] * samples\n",
    "            dp_log_prob_old = [0.] * samples\n",
    "            phi_log_prob_old = [0.] * samples            \n",
    "\n",
    "            for e in range(epochs):\n",
    "                for b in range(batches): \n",
    "                    start = time.clock()\n",
    "                    losses = 0.\n",
    "                    d_elbo = 0.\n",
    "                    idx = np.random.choice(np.arange(self.model.N), batch_size, replace=False)                                        \n",
    "                    \n",
    "                    if n > .9:\n",
    "                        for s in range(samples):\n",
    "                            eps = npr.randn(D)        \n",
    "                            z = np.exp(log_sigmas) * eps + means\n",
    "                            p_log_prob = model.p_log_prob(idx, unflatten(z))\n",
    "                            q_log_prob = model.q_log_prob_sep(means, log_sigmas, z)                                         \n",
    "                            dp_log_prob, _ = flatten(grad_p_log_prob(idx, unflatten(z)))\n",
    "                            g =  model.grad_params(dp_log_prob, eps, log_sigmas)                        \n",
    "                            d_elbo += g\n",
    "                            losses +=  (p_log_prob - np.sum(q_log_prob))\n",
    "                                        \n",
    "                            z_old[s] = z\n",
    "                            dp_log_prob_old[s] = dp_log_prob\n",
    "                            phi_log_prob_old[s] = model.phi_log_prob_sep(eps)                                                                     \n",
    "                        loss = losses/samples\n",
    "                        d_elbo /= samples                                            \n",
    "                    else:                         \n",
    "                        for s in range(samples):                            \n",
    "                            eps = (z_old[s] - means)/np.exp(log_sigmas)                            \n",
    "                            phi_log_prob = model.phi_log_prob_sep(eps)                                         \n",
    "                            w = np.exp(phi_log_prob - phi_log_prob_old[s])                            \n",
    "                            g =  model.grad_params(w * dp_log_prob_old[s], eps, log_sigmas)                        \n",
    "                            d_elbo += g                            \n",
    "                        d_elbo /= samples                                             \n",
    "                    n = npr.uniform()\n",
    "                    means_old, log_sigmas_old = means, log_sigmas\n",
    "                    means, log_sigmas = adam.update(d_elbo, np.concatenate([means, log_sigmas]), learning_rate)\n",
    "                    if np.sum(np.isnan(means)) > 0 or np.sum(np.isnan(log_sigmas)) > 0:\n",
    "                        means, log_sigmas = means_old, log_sigmas_old\n",
    "                        learning_rate = learning_rate * .9   \n",
    "                        n = 1.\n",
    "                    self.F[f] =  -loss                \n",
    "                    stop = time.clock()\n",
    "                    self.time[f] = stop - start\n",
    "                    f+=1                    \n",
    "                if e % 1 == 0:\n",
    "                    pstate = 'Epoch = ' + \"{0:0=3d}\".format(e) + ': Loss = {0:.3f}'.format(self.F[f-1])\n",
    "                    print (pstate, end = '\\r')\n",
    "                    sys.stdout.flush()  \n",
    "        self.params = {'means': unflatten(means), 'log_sigmas': unflatten(log_sigmas)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 500)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameters\n",
    "N = 50000\n",
    "K = 500\n",
    "D = 1\n",
    "x = 5 * npr.randn(N*K).reshape([N,K])\n",
    "alpha = np.ones(K)\n",
    "w = npr.normal(0, 1./np.sqrt(alpha))\n",
    "y = np.matmul(x, w) + npr.randn(N)\n",
    "data = {}\n",
    "data['x'] = x\n",
    "data['y'] = y\n",
    "data['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 079: Loss = 361690043.959508\r"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR4AAADdCAYAAABtwh14AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4FFW6+PFv9b5kIwuBBAIBWQRkCSiCLCPoiCAKSMIA\nBsZB0VGYq8MoLsyI6IC48jMjV5ELCAiyiAwDFxxldbiKiKCgbKKyLwlZO0nv9fujSUNISEJId4fk\n/TxPnnTXdt4u0i/nnKo6R1FVVUUIIYJIE+oAhBD1jyQeIUTQSeIRQgSdJB4hRNBJ4hFCBJ0kHiFE\n0NXZxPPdd9+Rnp5e6XZHjx5l8ODBZZYvWLCA119/PRChCVHv6UIdQCC8//77rFmzBrPZXOF2q1ev\nZuHChWRnZ/uX2e12nn/+efbu3ctvf/vbQIcqRL1UJ2s8SUlJZGRk+N8fPHiQ9PR00tPTmThxIgUF\nBQBERkayePHiUvs6HA6GDh3Ko48+GtSYhahP6mTiueuuu9DpLlbm/vrXv/LCCy+waNEi+vTpw9y5\ncwG4/fbbsVgspfaNjIykV69eQY1XiPqmTja1LnfkyBFefPFFAFwuF82bNw9tQELUc/Ui8SQnJzNz\n5kwSEhL4+uuvyc3NDXVIQtRr9SLxTJ06lcmTJ+N2u1EUhb///e+hDkmIek2Rp9OFEMFWJzuXhRC1\nW51qatntdvbt20dcXBxarTbU4QhRb3g8HjIzM+nQoQMmk6nS7etU4tm3bx+jR48OdRhC1Fsffvgh\n3bp1q3S7OpV44uLiAN+Hb9SoUYijEaL+OHPmDKNHj/Z/BytTpxJPSfOqUaNGNGnSJMTRCFH/VLWL\nQzqXhRBBF9LE4/V6+dvf/saIESNIT0/n6NGjpdZv2rSJ+++/nxEjRrB8+fIQRSmEqGkhTTyff/45\nTqeTZcuWMWnSJF555RX/OpfLxYwZM5g3bx6LFi1i2bJlZGVlhTBaIURNCWkfz65du+jduzcAnTt3\nZt++ff51R44cISkpicjISAC6du3Kzp07ufvuu0MSa22hqiqKopRa5vV4UDSaMssrkn82k8LsPKIS\n4zFHhFdpH3uBjbzT57Bl5aDR6dCbjRjMJvQmI/oLv3NPnuHnr/aQffw0epORmGYJRCU2QlEUvB4P\nXo/3wm8PXrcHV7EdZ1ExziI7zkteu4rtACgaBXtBIfZ8GxqdDp3RgN5oQHfhR/V68bjcuJ0uPC4X\nHqcLj8uNx+VC0WqJa9GU8IYxnPvpKAXnzuMs8h1XZ9CjNejR6rSgKCglPxrf/8UuuwNnsR2NVove\naECj0/piLXag0WowWi0YrGYMFjNGqxkUBVexHZfdiavYjsftpjg3n+K8AhSNBo1Oh1anRdFq0Wgv\n+f9eVVFV378rQFhMFFGJjXA7HOSePIvBYsYcFQGqSnFeAQ5bIV6viur1+vZRS177jqF6vReOeeHH\n69vGYDERldgIr8dDUU4ebofTt4/X6z9WyXFM4VbC46LRGvS4HU6SurSn98O/q/LfVlWENPHYbDbC\nwsL877VaLW63G51Oh81mIzz84hfCarVis9lCEWZAOQqLsBcUUpxXgC0rG1tWDrasbAwWMw1vaMbp\n/Uf4Zvk6zh89iS0zm4LMbIxWC5YGEbjsDuz5Nlx2B5aoCOLbtCCmeRMaJMZjigjzfWELCnHbHQAY\nLCYsDSI5vudHfvj0C98fKaAzGFC0GuJbJ5OU0h63w0nh+Vxs53MozM7D43JRlJ2Ho7AolKdKhEhM\n8yb0emjEVf3HVpmQJp6wsDAKCwv9771er384i8vXFRYWlkpE1xO308kX73/EtveWktC+FalvTiEi\nPpbP35rH6udex+10VnoMU0QYEQ1jiGvZDIetkKLcfCwNIolplojBaiH/TCZHd+3jlx17qhRT81s6\n0aRjW3JPncWWlYPH5ebM/p848d1+/zY6owFrdBQ6o4GGrZoT2TiOyMYNCY+Lxuvx4iy2X6ix5OOy\ne3DZXVijI2lxaxfiWyfjLLaTffQkOSfP4nWdx+M4CWohlrjb0OrNaDRevM796M16IhL6olHOoTdq\nsTbshM6owV18FFfxGcLiWqF4D1NwegOWuFQ0xrZkHXgdj1uHJbo7OpMVnTkSg7kBHvsv2E7OweP4\nCZVwCm0dcBQ3IizyCEbjAXQGBxpdJGjjcOQdwesBVQVUUNGjoEFVQat3oDOogBm3w47XA6aIRuiM\nOtyOHFwOHTprX1zFHnKPbwBAb1DRGjTo9B40WhWj1feDCl6v4ivLC16P7/z6v8eK77WqgqMoCru9\nNe7CXYTHeHE7FRyFCihgtIDB7EXRqiiX7KcoZV8DKJqL27nsCgXnNWg0YApT0RlUFM2l+6ooChij\nuhLdbjm2zPN43B70RgPRSQk1mnQgxIknJSWFzZs3M3DgQPbs2UPr1q3961q2bMnRo0fJzc3FYrHw\nzTffMG7cuBBGWzW5p85y/Lv9nPD/HCDr1xP+psPJvQfZt34rMc2bcOK7/UTEx9K6b3dMEWGExTYg\nLDaasJgo7LYizh3+lYj4GLqlDaLhDc0rLdvjdpN/Nou8U2exFxRiCrdiDA9DbzIC4Cwsoig3n7DY\naBq1aYGqqjjz96I1xKAzJ+J2Osk8cgxjmAVrTAMMZhPO/O/xemyoHjseZzaW2N+gNcbhceWC6sae\n8w1ndo9Fo4sgqsVEXIVHUDQ/YAhXMVhvwNbqALZTy/E4L/bPWeNNWBvdx/n9z/uXa3Sr8LrzAdC6\nYvEU5aBVPWgBd6ZvP5MBvHlfoDElEhV94sLR1oEbKACXb3w3LOEKlhb9cRX+QkTR9gvbaTBGdERv\nbYk95ys8rpNEJdyOOcY39lJx1lZUTxEqvqaKztQYVfXgLj6GIawNKBqKs7aABrQxzfE6c3DbV4MJ\nGjbrTINWT+MuPkHBqRVodGHoLc3RmZuioMHtzMSR+y06cyKRzcZjz92Jq/AXtPooNPootIYYFK0F\ne+7X2E4ux+PcgTEyhagWE9FoLaBo0eqjMUTcRNG59TgLf8IS2w9DeDtUTyGOvO/RW1uiNUTjyP8e\nR94eVK8TU9TNAHjd+Wh0EXg9RbjtJ3HbT6M3N8Ec0wcAd/EJ3PbTKFozpqiu6EwNiWrc8Kr/9q9G\nSB8S9Xq9TJ06lUOHDqGqKtOnT+fHH3+kqKiIESNGsGnTJt555x1UVeX++++v9K7kEydO0L9/fzZu\n3Bj0+3hO/XiYdS9lsGvFerwej3+5KSKM6KYJ3HhHTwY880f2rP43Hz89E3uBjfYD+vLggleJiK/a\nTVfV5So+Ts7hV4ls/gjGiA4AFGVt49z3f8RdfAyNvgFx7V+n4ORHeN02whoPRaOPpODEEorPby11\nLJ0lmQbJE8nc/wx4nYCCojECKqrXUW75WmNDLLH9MMf0puDkCorPbwFA0VqJSn4MryufglPLMUf3\nQqOzUnR+G3pzEobwDujNTXAWHkFrjMMc3ZNze/+Ex36KyOaPEdZ4CPacL0FV8biy8Thz0FuSscYP\nxBjR3vfZC3/GaduPqUF3tIZYoKQ/RUVRqn9tRfW6yT+xCFfhz0S3egaNzlrtY5U6rseBs/AnDOFt\nUZTr57Gfq/3u1amn00OReDxuNxtnzWf182/gdjpJvKkNXYbdRdPO7Wja6UZimjcpU011FtuxF9iI\naBhbY3EUZW6k6PxWTJFdscYPBEWHPWcHektzTu9MxZG/B60hlsQen6IzJXBsazfcjnNYG/6WwnMb\nQC1Jlgpw8U/CEncnxsjOKBoDbvsp8o/N922lC8cUdQtedz6x7WagNcRSfH4rxohOoHpxFPyAy3YI\nQ8RNhCcMR9HofefLlcPpr4ej0UcS1+FN9JbmV/U5Pc4snAUHMEXfVuPVf1F9V/vdq1N3LgeSqqps\nm7OU3JNnSxZw6sfD7P98O/Z8G+ENY3jg3ZfpPOS3lX4hDGYTBnPlD9KVx2k7jNeVi6mBrxqtehzk\n/voO5w9MpSRhWBoOwBjZmZzDF29PMEam4Mj7lpNfDcQQ3gG3/SQNbniamDZ/pfDsOnJ+/gcNWkzA\nGNnVl4gAQ1hrzNE9S50DrT6GwnPrie80B2Nkx9Kfy9rS/7okvstp9Q1octvGan12AK0h1t88Etcv\nSTxV9OvO7/nw0Slllsc0b0L30fcxeOp/1WgNpjyq18mpr4fgtp8mqe9OHDk7yfzxabyuHLTGxsS1\nf5W8o3MpOreBonMb0JkS0Rpi0RiiadxtGfnHFnD+wN8oztroazLd8BcArPGDsMYP8pcTmfT7cstX\nFIWYti8Q0/aFgH5OUfdJ4qmiw1/sBODeaU/Sum93AKIS42nYslnQYsg/8SHu4mMAnN3zEI6879Bo\nzUS1+BNRyRPQmRpjie3Hia/uxl10lMa3rMIY3s6/f1TyHwlPTMN2+p+Yo3ui0VY8/Y8QgSKJp4p+\n+s83APQYO4yYpMSgl696XeT89AaKxoQ+rDWO3G8AhUYpi7DE9fNvp9FH0PS2LXg9hWj1UWWOozXE\nENnsD0GMXIiy5CHRKlBVlSPbd9GgaeOQJJ38E0s5uiUFd/FRIpIepOFNb6MxxBDT9qVSSaeEotGX\nm3SEqC2kxlMF5w7/QkHmeW4ZWXaq40DLOfIm5w+8gKIxE9F0LNGtn0erjyT5jiPX1eVWIS4liacK\nDl9oZrW8rWtAy8n5OQPbyeUYo7oR3uR3FJ37Nzk/vYrO1ISE7mswhLXybytJR1zPJPFUwZHtuwC4\noVf5l4irw+uxU3h2LZaYvmiNcRSe+4zz+58HVBz5e8g/5pvtVG9pQUL3f6G3JNVY2UKEmiSeSvzw\n6Ta2z1uBKSKMxA6tK9+hChz5ezm7+w84bQfQGuIIbzKa/GPzUTQGEm9dj9dTRO7Pb+N1F9AoZSE6\nkwzjKuoWSTwVsBfY+J8H/gxAx0G3o6mBmStU1cvpb36Hu/gY1viBFGZ+Tu7Ps1B04TTsONt/450l\ntu81lyVEbSWJpwIb/98CbFnZ9Js4lrRZf62RY9pzvsZdfIzwxJHEd56Do2A/9uzthCUMlytRot6Q\nxHMFhdm5fPraHMJioxny90loNDVz54Ht9CcAhCUMB8AYfiPG8Btr5NhCXC/kPp4r2DJ7MfZ8GwOe\neRRTeFjlO1SBqnqxnf4Ejb4Bltjf1MgxhbgehbTGY7fbeeqppzh//jxWq5WZM2cSHR1dapsFCxaw\nbt06APr27cuECRMCHpfb5WLL7MWYwsPoM77mhny053yFx3Ga8CbpKBpDjR1XiOtNSGs8S5cupXXr\n1ixZsoQhQ4Ywe/bsUuuPHz/OmjVr+Oijj1i+fDn/+c9/OHDgQMDj+vbjDeSdPsdtfxheY7UduLSZ\nNazGjinE9SikiefSwd779OnDl19+WWp9o0aNmDt3LlqtFkVRcLvdGI3GgMbk9XhY+ZcZKIrC7RPG\n1Nhxfc2s1b5mVoxcsRL1W9CaWitWrOCDDz4otSwmJsY/jrLVaqWgoKDUer1eT3R0NKqq8uqrr9Ku\nXTuSk5MDGuehrTvIPXmGhA6tqzTcaFXZc77E4zhDRNMx/kGxhKivgpZ4UlNTSU1NLbVswoQJ/gHd\nCwsLiYiIKLOfw+Hgueeew2q18sILgR8HpjAnD4CUYXfV2DFV1Yvt1IVmVmNpZgkR0qZWSkoKW7f6\nxvTdtm0bXbuWfhZKVVUee+wx2rRpw7Rp06o8L/O1cDt8Mz5EJsTXyPGyD7/KkfUx5B2bi0Yf7R9g\nW4j6LKRXtUaOHMnkyZMZOXIker2eN954A4D58+eTlJSE1+vl66+/xul08sUXXwDw5z//mS5dugQs\nppLEozfWzFUn2+lVAOiMjYho9pA0s4QgxInHbDbz9ttvl1n+4IMP+l/v3bs3mCH5E4+uBhKPx5WH\ns+BHTNG30aTH+ms+nhB1hdxAeJlrTTxFmZtwFfvmfPKNEqhibtC9psITok6QxHMZ1zUknvzjizn1\n9X1k/fA0AMU5OwAwSeIRohRJPJepbo3HnreHzH1P+F7nfo2qqtj9ieeWmg1SiOucJJ7LVLdzOeen\n11G9DnTmZngcZ3EXH8eeuxO9tTVaQ0wgQhXiuiWJ5zIXazxVv0Pa6ymiKPMz9NYbiLgwJ1Xesbmo\n7gJpZglRDkk8l/EnHkPVL3sXZW5E9RRhbXQvpijfvUi5v7wDQFjjITUfpBDXORmP5zJX07nsKvwZ\njyuXwjNrAAhrdB96awvfSq8TrbEhltiy088IUd9J4rnM1XQun/l2LI78PYAGnbkpxsguKIqC3noD\nrsKfCE9IQ9HIKRbictLUuozb4QAqTzyq6sVp2w8ogJewhOEoigKAObonoBDeZHRggxXiOiX/HV/G\n7XQBlScej+McqteBtdEQoltNxhB2cQaKmLYvEZH0IMaIDgGNVYjrlSSey1T1crqr6FffdpZmZRKM\n1hCN1hBdzl5CCJCmVhlV7eNxFx8FQG9uFvCYhKhrJPFcpiTxaPUVX053FR0DQGeRxCPE1ZKm1mVc\nDic6o8HfUXw5rysfNDrcxb8CvqaWEOLq1PpZJgC8Xi/jx4+nf//+jBw5MqAxuS8knvKoqsqxL27D\nEHYDqvdCJ7RZ5jQX4mrV6lkmSsyaNYv8/PygxOR2ONFf4XEJrzsXd/GvFGV+jiNvD1pjPBqtOShx\nCVGX1OpZJgA2bNiAoij+7QKtohqPu/iU/7XXnScdy0JUU62eZeLQoUOsXbuWt99+m3feeScocbod\nTvRmU/nr7KdKvddZmgchIiHqnlo9y8Tq1as5e/YsY8eO5eTJk+j1ehITE+nTJ3ADprscTsxRZWe7\nAHDbTwKgaIyoXgd66d8RolpC2rlcMstEx44dy51l4umnn/a/zsjIIDY2NqBJByppal2o8UQ0e4i8\nX97BGNW13O2EEBULaR/PyJEjOXz4MCNHjmTZsmX+edHnz5/Pxo0bQxKTr3O5/MTjuZB4IpMepHn/\nw1jjBwUzNCHqjFo/y0SJiRMnBjwer9eLx+VCe4WxeEpqPDpTAhpdeMDjEaKukjuXL+Gp5AFRt/0U\nGl2kJB0hrpEknku4LgyJcaWmltt+Cp2pcTBDEqJOksRziYpqPF5PEV5XDlpTYrDDEqLOkcRziYqe\nTL+0f0cIcW0k8VyiovGWS+5alsQjxLWTxHOJigYBK7l5UGeWxCPEtZLEc4mKm1q++dB10scjxDWT\nxHOJChNP8XFARhwUoiZI4rmEq4JZRP0jDpqbBjUmIeoiSTyXqLjGcwyNPhqNzhrssISoc64q8bjd\nbrKysnC73YGKJ6Qunb44//giPM5swDfyoLv4uAxzKkQNqdKzWmvWrGHx4sXs27cPVVVRFIX27dvz\nwAMPcN999wU6xqApmcwPzwnOff8WYY2H0ihlIR5nJqrXLs0sIWpIpYlnypQpfPzxx/Ts2ZMnnniC\nBg0akJ+fz86dO3n22WfZuXMnL7/8cjBiDbiSGo9G60tAttOf4Mj7DlUtGV9ZEo8QNaHCxLN27VrW\nrl3LvHnz6NGjR6l148aN45tvvuGRRx6hZ8+eDBw4MKCBBoPLn3guNiXPH5zmn4pYrmgJUTMqTDxL\nly5lwoQJZZJOiW7dujFx4kSWLl1arcRTlVkmtm7d6h/29KabbmLKlClXnHrmWvnn1NL5ajiKxkxR\n5r/R6H0jEkqNR4iaUWHn8qFDh+jXr1+FB7j99ts5ePBgtQqvbJYJm83Ga6+9xrvvvsvy5cuJj48n\nOzu7WmVVhb+ppfH9jmj2B18cp1YCMoeWEDWlwsTjdrvRarUBK7yyWSZ2795N69atmTlzJqNGjSIu\nLo6YmJiAxeNPPDpfH09YoyHoLmleSY1HiJpRYVOrdevWbNmyhbFjx15xmy1bttCmTZtKC6rOLBM5\nOTns2LGD1atXY7FYGD16NJ07dyY5ObnS8qrjYudyyTTGUUQmPcj5g1PR6CLQ6qMCUq4Q9U2FNZ7U\n1FQyMjL4/vvvy12/e/du/vGPfzB69OhKC0pNTfV3Vpf8hIeHVzjLRFRUFDfddBNxcXFYrVa6devG\n/v37q/rZrpr7wng8Go3d91sXTnjTMaAxoLe2DFi5QtQ3FdZ4hg8fzpdffsmoUaP4zW9+Q5cuXYiK\nisJms7Fr1y42bdpEamoqAwYMqFbhlc0y0b59ew4dOkR2djYRERF89913pKWlVausqrhY4yn2/daF\no9FHkHjLP9FIbUeIGlPpfTxvvPEG3bt358MPP2Tjxo2oqgpAhw4deOWVV7jnnnuqXfjIkSOZPHky\nI0eORK/X88YbbwC+WSaSkpLo378/kyZN4qGHHgJgwIABtG7dutrlVeZi57Iv8Si6MADMMb0CVqYQ\n9VGV7lxOS0sjLS0Nu91Ofn4+UVFRGAzlj0t8Naoyy8SgQYMYNCg408iU3Mej1RShaMNQFHmUTYhA\nuKrpbUwmEyaTCbfbzdatW1FVlR49emAs52nu69HFGk+RzCQhRABVmniWLFnCP//5TxRF8ffnjB49\nmgMHDgDQqFEj5s2bR4sWLQIebKCVPKulaGxodNGVbC2EqK4K2xLvv/8+r732Gm3atKFz58689dZb\njBs3DlVVWbJkCYsXLyY2NpZZs2YFK96A8td4FJvUeIQIoAprPCtWrGD69OncfffdANxzzz0MHz6c\n9957j5SUFACee+45/9TD17uLz2rZJfEIEUAV1nhOnTpFx44d/e87dOiATqejadOLd/A2bdqUvLy8\nwEUYRP5ntfRI4hEigCp9ZMJkMpVaptfr0esvzi2uKAperzcw0QWZ2+FEURQ0WtDoJfEIESiVXi8O\n1JPgtY2z4ADOwvPojHoUBTRaSTxCBEqlV7VmzJhRqtbjcrl48803CQvz3Vxnt9sDF10QZe1/nuLc\nn9AafJ9LmlpCBE6Fiefmm2/mzJkzpZZ16dKFrKwssrKy/Mu6desWmOiCyOvOw+NS0el9NTxpagkR\nOBUmnkWLFgUrjpBTvS48LgWNzgOARhdRyR5CiOq65mcCDh48yNNPP10TsYSUqrpwu0CrvfCEujS1\nhAiYa048586d41//+ldNxBJSqtd5ocZTMhhYWIgjEqLukqcgS3hdeNyg1fuevlekqSVEwFzVQ6I1\nrSqDvS9ZsoSVK1eiKAqPPvood955Z0BiUVVfH4/uwhmRppYQgRPSGk9lg70XFhYyd+5cPvroI+bN\nm8f06dMDFovX7cDrVvw1Hkk8QgROhTWeqvTdlDylXh27du3yD/LVp0+fMomn5ObF4uJiiouLA3oz\no2/YUx3aCzdlS+IRInAqTDxPPfVUjRVUncHeLRYL99xzD4MGDcLj8fDII4/UWDyXczvd+BKP1HiE\nCLQKE09VazM5OTmVbpOamkpqamqpZRMmTKhwsPdvv/2W3bt3s3HjRsA3e2lKSkqpB1drgsvuIP+c\nb/ZQnR5QdCgaU8U7CSGqrcI+nsGDB5d58nzFihXYbDb/+6ysLHr27FmtwksGewfKHey9qKgIk8mE\nwWDAaDQSHh5Ofn5+tcq6EpfdwbPNezPvj77L5zqDikYXXm+eURMiFCqs8Rw+fBi3211q2YwZM7j1\n1lv9z2oB/gHgr1Zlg73369eP7du3k5qailarJSUlhdtuu61aZV1J/tks8s9mERnvIbG9gS4Di9Ho\nEmq0DCFEaVd9Ob28JFPd2kFVBnufPHlytY5dVfYCX+2tRTcn907pSHH2F/K4hBABFtL7eGoDe4Gv\nj0lvUlG0ZmLbvYrOGB/iqISo2+p94nHYfInHYFZRNAaimo8PcURC1H31/pGJkhpPSeIRQgRepTWe\nhQsXYjab/e89Hg9LliwhMjIS8F15up45bL74DWYVRan3FUAhgqLCb1pCQkKZu5djY2P59NNPSy1r\n3LhxzUcWJCWdy1LjESJ4Kkw8mzZtClYcIVOqc1kSjxBBUe/7eC5taqHoK9laCFET6n3i8XcuW7wo\nGkk8QgRDvU88/svp0tQSImjqfeIpdTldmlpCBIUknpLOZbMK0tQSIijqfeJx2ApRNAp6I9LUEiJI\n6nXiUVUP9oJCjFYjioI0tYQIknp9q+7xL3pRlJ2Pweqr6UiNR4jgqBU1ns8++4xJkyaVu2758uUM\nGzaMtLQ0Nm/eXGNlej1FOAv24bA5MPoTj9R4hAiGkNd4Xn75Zf7zn/9w4403llmXmZnJokWL+Pjj\nj3E4HIwaNYrbbrsNg+HaayYeh2/ud0eRlwZNLiQcaWoJERQhTzwpKSnccccdLFu2rMy677//ni5d\numAwGDAYDCQlJXHgwIEaGXPZ4zyH1wNuBxitvoQjTS0RTKtXr2bx4sX89NNPKIpCmzZtGDNmDAMH\nDvRv4/V6WbZsGatXr+bnn3/G4XDQrFkzBg0axIMPPojRaARgx44djBkzxr+foiiYzWZatWrF2LFj\nGTRoUNA/X0WClnjKm2Vi+vTpDBw4kB07dpS7j81m889CAb6ZKC4d7/laeByZuOy+kRMNJYlHnk4X\nQbJs2TJmzpzJlClT6Nq1Ky6Xi88++4w///nPOBwOhg4ditvt5pFHHuHHH3/k8ccfp0ePHhiNRnbv\n3s2sWbP46quvmD9/fqkRQD/55BPi4uLwer3k5OSwbt06Jk2aRG5uLqNHjw7hJy4taN+08maZqExY\nWJh/FgrwzURxaSK6Fh5nJs5i3z+Y0aIFpMYjgmfZsmWkpaUxbNgw/7IbbriBX3/9lYULFzJ06FDm\nzZvHjh07WLVqFa1bt/Zv16RJEzp16sTdd9/N1q1b+c1vfuNfFx0dTVxcHADx8fG0bduW4uJiXn/9\nde6+++4yM/WGSq3oXL6Sjh07smvXLhwOBwUFBRw5cqTUP8C1cDvO+ROPQRKPCDKNRsO3335bZi65\nyZMnk5GRgaqqfPjhhwwZMqTcv/mkpCT+93//l759+1Za1tixYykqKmLLli01Ff41q5Vti5JZJvr3\n7096ejqjRo1CVVWefPJJf5v2WnmcWRcTj+nCAPbSuSyCZNy4cTz55JP07t2bW2+9lZtvvpmePXty\n4403Eh0dzfHjxzlz5gy33nrrFY/RrFmzKpXVtGlTzGYzhw4dqqnwr1mtSDzdu3ene/fu/veXzjKR\nlpZGWlrvXrpzAAAQPUlEQVRajZfpcWTivNDHozd7ALmcfr3K2v88ttOrQ1J2WOMhxN7496ve7+67\n7yY+Pp4PPviA7du3+28VadeuHa+++qq/L7NBgwal9rv33ns5fvy4//3gwYOZNm1apeVFRETUWP9o\nTagViScUPJc2tUy+ucOkqSWCKSUlhZSUFDweDz/88AObNm1i8eLFPPzww8yfPx+gzISa7777Li6X\nC/A1y5xOZ5XKuvxCTajV38TjzMR1IfHojb5/SHlk4voUe+Pfq1XrCJXTp0/z3nvv8cQTTxAVFYVW\nq6Vjx4507NiRbt26MW7cOPLz84mNjeWbb74pdXk9IeHiZJMmU9Wm2T569CiFhYW0a9euxj9LddXq\nzuVAuvSqls5oB6TGI4LDaDSycuVKNmzYUGZdeLhv+uy4uDhGjx7NqlWrOHLkSJntnE4n2dnZVSpv\nyZIlhIWFcfvtt19z7DWlXtZ4VNWLx5GFs9jXUa03FPtWSB+PCILo6GjGjRvH9OnTOX/+PHfeeScG\ng4FDhw7x1ltvMXToUBISEhg/fjx79+5l5MiR/PGPf6RXr16YTCb27NnDnDlz+OWXX0hPTy917Ozs\nbLRarf8+nvXr17Nw4UKmTZtWatrxUKuXicfrPA94/TUevdGXeKSpJYLlySefpFmzZixfvpx58+bh\ncDhISkpi2LBh/P73vwdAp9Mxe/Zs/vnPf7Jq1SreffddioqKSEhIoFevXmRkZNC8efNSxx06dCjg\nu3M5JiaGNm3a8O6771bpsnsw1cvE43b6ntPyN7X0vt5+aWqJYBo2bFipGwjLoygKQ4YMYciQIRVu\n1717dw4ePFiT4QVUvezj8TgyAXA7LQDo/X08UuMRIhjqZ+JxngPAdSHxGMy+GwilqSVEcNTPxHOh\nxuNy+C5HliQepKklRFDUyz6eo7v288X7YZw+4OtU1l94ZEKaWkIER71MPPs3n+P7f5uBYhokutFo\nATQoijbEkQlRP9TLxJOWsYR+TxzCUXAI2y++MUrkipYQwVMvE49Go6Fhq7Y48t04TvuWSeIRInhq\nRedyRYO9L1iwwD+I2D/+8Y8aLVfRXvKsi4w+KETQhPzbVtFg78ePH2fNmjWsWLECjUbDyJEjueOO\nO2jbtm2NlK3RWvyvpcYjRPCEvMaTkpLC1KlTy13XqFEj5s6di1arRVEU3G53jQ0EBqBozRdfS+IR\nImhq9WDver2e6OhoVFXl1VdfpV27diQnJ9dYTBrNJTUeuXlQBNEzzzzDmTNnWLBgwRW32bp1K++/\n/z4//PADqqqSnJzM8OHDGTVqVKkB3gHWrVvHsmXLOHToEIWFhSQkJHDHHXcwfvx4IiMjAThx4gT9\n+/cvtZ/JZKJ58+akpaWVe9xAqdWDvQM4HA6ee+45rFYrL7zwQs0GpTEACqDKPTyiVvniiy94/PHH\n+ctf/sKLL76IVqvlyy+/ZMaMGeTk5DBhwgT/tlOmTGHdunU88sgjTJkyBavVyoEDB8jIyGDr1q2s\nXLmy1Ng9s2fPpmPHjqiqSkFBAZs3b+aVV17hxIkTTJ48OSifL+R9PBVRVZXHHnuM7t27M378+Bo/\nvqIoKFoLqqdQ7loWtcry5cu5/fbb/U+qAzRv3pzMzEwWLlzoTzzr1q1jxYoVzJ07l969e/u3TUxM\npFu3bvz2t7/l448/LjW1TWRkpH8mioYNG9KyZUt0Oh0zZ87k/vvv54Ybbgj45wt5H0955s+fz8aN\nG/n888/5+uuv+eKLL0hPTyc9PZ3du3fXaFmaC/080tQStYlGo+HHH3/k3LlzpZb//ve/LzX55aJF\ni+jZs2eppFMiMjKSlStXMmLEiErLS01NxWAwsH79+msPvgpqRY2nosHe9+7dG9CySzqYpal1/Vr5\n1Ax2rfjfkJTdNXUgw197tsaPO3bsWMaOHUu/fv24+eabueWWW7j11lvp1KkTERERALhcLr777jue\neOKJKx6nadOmVSrParXSpEmToM1EUSsSTygpmpLEI00tUXukpKSwatUq5s2bx5YtW/i///s/wDef\n1owZM+jWrRs5OTl4vd4yM1E8+uijpS7YdO3alblz51ZaZjBnoqj3icd/L480ta5bw197NiC1jmBY\ns2ZNqYsml05X06pVK2bMmIGqqhw8eJBt27axcOFCHn74YT7//HOioqJQFIXc3NxSx3zxxRex231j\nTL355ptVHpvZZrP5+34Crd4nHmlqiVDq168fnTp18r8vmbb7zTff5IEHHiA5ORlFUWjbti1t27bl\nzjvvZMCAAezcuZMBAwbQvn17du3aVeqY8fHxpY5XlcRTXFzML7/8wqBBg2ruw1WgVnYuB9PFxCNN\nLRF8YWFhNGvWzP8TExOD2Wxm7dq1rFq1qsz2JXNjxcbGAjBmzBi2bdvGV199VWZbVVXLdE5fyYoV\nK/B6vaWm0gmkel/jkataorbRaDRMmjSJF154AZfLxeDBg4mIiODnn3/mv//7v+nevTvdunUD4L77\n7mP37t2MHz+ehx9+mP79+xMREcGBAweYP38+u3bt4vHHHy91/Ly8PDIzM1FVlfz8fLZt28asWbMY\nP348SUlJQfmM9T7xKBf6eKTGI2qTtLQ0YmNj+eCDD/jkk08oLCwkPj6eQYMG8eijj5badurUqfTp\n04dly5bx0UcfkZeXR8OGDenevTvPPfcc7du3L7X9Y4895n8dFRVFy5Yteemll7jvvvuC8tlAEg+K\nxnTht9R4RPC88sorlW7Tr18/+vXrV6XjVWXbJk2a1JqZKOp9H49c1RIi+Op94pHOZSGCr94nHo2/\nj0dqPEIES71PPCWjEMpVLSGCRxJPSR+PNLWECJp6n3g0cueyEEFX7xOP/yFRaWoJETS1IvFUNMsE\ngNfr5aGHHmLp0qU1XrbOnACA1tiwxo8thChfyG8grGiWiRKzZs0iPz8/IOWbGvQkqc9O9GGtAnJ8\nIURZIa/xVDTLBMCGDRtQFKXcEdZqgqIoGMLbyvTFQgRR0BLPihUruOeee0r9fP/99wwcOPCKI9sf\nOnSItWvX8l//9V/BClMIEQS1epaJ1atXc/bsWcaOHcvJkyfR6/UkJibSp0+fAEUphAiGkPfxVOTp\np5/2v87IyCA2NlaSjhB1QMj7eMpTMsuEEKJuqhU1nopmmSgxceLESo/j8XgAOHPmTM0FJ4SoVMl3\nruQ7WJlakXhqSmZmJkCpycuEEMGTmZlJs2bNKt1OUVVVDUI8QWG329m3bx9xcXFotXJ5XIhg8Xg8\nZGZm0qFDh1LTJV9JnUo8QojrQ63sXBZC1G2SeIQQQSeJRwgRdJJ4hBBBV2cTj9fr5W9/+xsjRowg\nPT2do0ePllq/adMm7r//fkaMGMHy5ctDFGXlcS5YsIBBgwaRnp5Oeno6P//8c4gi9fnuu+9IT08v\ns7y2nM9LXSnW2nJOXS4XTz31FKNGjWL48OFlbpqtLee0sjirdT7VOurTTz9VJ0+erKqqqu7evVt9\n9NFH/eucTqd6xx13qLm5uarD4VCHDRumZmZm1ro4VVVVJ02apO7duzcUoZUxZ84c9Z577lFTU1NL\nLa9N57PElWJV1dpzTleuXKm+/PLLqqqqak5Ojtq3b1//utp0TiuKU1Wrdz7rbI1n165d/qE0Onfu\nzL59+/zrjhw5QlJSEpGRkRgMBrp27crOnTtrXZwAP/zwA3PmzGHkyJG89957oQjRLykpiYyMjDLL\na9P5LHGlWKH2nNMBAwb4R15QVbXUvWe16ZxWFCdU73zW2cRjs9kICwvzv9dqtbjdbv+68PBw/zqr\n1YrNZgt6jCWxXClOgEGDBjF16lQ++OADdu3axebNm0MRJgB33XUXOl3Zm91r0/kscaVYofacU6vV\nSlhYGDabjT/96U888cQT/nW16ZxWFCdU73zW2cQTFhZGYWGh/73X6/X/IV6+rrCwsNQ/cjBVFKeq\nqowdO5bo6GgMBgN9+/blxx9/DEmcFalN57Myte2cnj59mjFjxnDfffcxePBg//Ladk6vFGd1z2ed\nTTwpKSls27YNgD179tC6dWv/upYtW3L06FFyc3NxOp188803dOnSpdbFabPZGDx4MIWFhaiqyo4d\nO+jQoUNI4qxIbTqflalN5zQrK4s//OEPPPXUUwwfPrzUutp0TiuKs7rns049JHqpO++8k+3bt/O7\n3/0OVVWZPn06//rXvygqKmLEiBE888wzjBs3DlVVuf/++4mPj6+VcU6aNIkxY8ZgMBjo0aMHffv2\nDUmc5amN5/NKauM5fffdd8nPz2f27NnMnj0b8A2YV1xcXKvOaWVxVud8yrNaQoigq7NNLSFE7SWJ\nRwgRdJJ4hBBBJ4lHCBF0kniEEEEniUdU2TPPPEObNm2u+NOvXz/69evnv+QaCBkZGf7y/ud//qfC\nbefMmePfNpAxiatXZ+/jETXv+eefZ9KkSYDvTtbU1FRmz55Nx44dAfzP8FRlzN1rkZiYyLJly0o9\nalKeBx54gKFDh5a56U2EniQeUWXh4eH+2/YdDgcAkZGRxMXFBTUOrVZbpTItFgsWi0UG/q+FpKkl\natSlTa2MjAzGjRvH22+/TY8ePejSpQtTp07l1KlTPPzww3Tq1Im77rrL/8gIgNPp5JVXXqFXr16k\npKTwwAMPsGfPniuW5/F4mDlzJr1796ZDhw4MHjyY9evXB/xzimsjiUcE1I4dOzh27BhLlixhypQp\nLF26lLS0NAYPHsyqVatITk7m2Wef9W//9NNPs3PnTmbNmsXHH3/MrbfeSnp6Or/88ku5x1+yZAmf\nffYZGRkZbNiwgQEDBjBp0iSOHz8erI8oqkGaWiLgpk2bhsViITk5mddee43bbruNe++9F4CRI0ey\nefNmsrOzKSgoYP369axdu5ZWrVoBMGHCBHbt2sX8+fOZNm1amWMfPXoUs9lMYmIicXFxPPbYY3Ts\n2JGoqKigfkZxdSTxiICKi4vDYrH431ssFpo2bep/X9IR7XQ6/cMppKWllTqG0+nE6XSWe/xRo0bx\n2Wef0adPHzp06EDv3r0ZPHhwrR2WQ/hI4hEBVd5gXBpN+S18vV4PwEcffVTmypjBYCh3nxYtWvD5\n55/z5Zdfsn37dtatW8d7773H3Llz6dGjxzVGLwJF+nhErVHSvDp//jzNmjXz/yxYsKDMAOMlPvzw\nQ/7973/Tp08fnn32WdavX09ycjKffvppMEMXV0kSj6g1mjVrxsCBA/nrX//K1q1bOXbsGG+99RYf\nffQRLVu2LHcfm83GSy+9xObNmzl58iQbN27kxIkTdOrUKcjRi6shTS1Rq7z88su88cYbPPfccxQU\nFNCyZUsyMjKu2Gx66KGHKCoqYtq0aWRmZtKoUSMmTpzI0KFDgxy5uBoyEJi4rmRkZLBmzRo+++yz\nKu/Tr18/hg8fzmOPPRbAyMTVkKaWuO54PB4yMzMpLi6ucLuioiIyMzPxeDxBikxUlSQecd05efIk\nvXr1YsmSJRVut3jxYnr16sWZM2eCFJmoKmlqCSGCTmo8Qoigk8QjhAg6STxCiKCTxCOECDpJPEKI\noJPEI4QIuv8PVMh5LVot5jYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3202ebbd50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "batch_size = 5000\n",
    "seed = 1234\n",
    "learning_rate = 0.1\n",
    "samples = 1\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "model = LinearRegression(data, N/batch_size) \n",
    "sns.set_style(style='white')\n",
    "\n",
    "npr.seed(seed)    \n",
    "params = {}\n",
    "params['means'] = {'w': npr.randn(K), 'tau': 1e2 * npr.randn(1)} #, 'alpha':  npr.randn(K), 'tau': npr.randn(1)}\n",
    "params['log_sigmas'] = {'w': npr.randn(K), 'tau': 1e-2 * npr.randn(1)} #, 'alpha': .1 * npr.randn(K), 'tau': npr.randn(1)}\n",
    "inference = Inference(model, params)  \n",
    "inference.run(13, batch_size, samples, learning_rate, 'SGD')\n",
    "plt.plot(np.cumsum(inference.time), -inference.F, color = colors[1], label = 'SGD')\n",
    "\n",
    "\n",
    "npr.seed(seed)    \n",
    "params = {}\n",
    "params['means'] = {'w': npr.randn(K), 'tau': 1e2 * npr.randn(1)} #, 'alpha':  npr.randn(K), 'tau': npr.randn(1)}\n",
    "params['log_sigmas'] = {'w': npr.randn(K), 'tau': 1e-2 * npr.randn(1)} #, 'alpha': .1 * npr.randn(K), 'tau': npr.randn(1)}\n",
    "inference = Inference(model, params)  \n",
    "inference.run(80, batch_size, samples, learning_rate, 'iSGD')\n",
    "plt.plot(np.cumsum(inference.time), -inference.F, color = colors[0], label = 'I-SGD')\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(4,3)\n",
    "plt.ylabel('ELBO', fontsize = 15)\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.xlabel('Time[s]', fontsize = 15)\n",
    "plt.xticks(fontsize = 10)\n",
    "plt.yticks(fontsize = 10)\n",
    "plt.legend(loc = 4, fontsize = 15)\n",
    "plt.savefig('/home/sakaya/MUPI/papers/uai17importance/linear.png', dpi=300, bbox_inches= 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06467827,  0.59002482,  0.37859894, -0.53644583, -0.6892309 ,\n",
       "       -0.99776871,  0.03972797,  0.4601806 ,  1.12462771, -0.41590812,\n",
       "       -0.86359898, -0.06527568,  0.5332345 , -2.35558899, -0.82688293,\n",
       "        0.0692633 , -1.160286  ,  0.04392596, -0.76753021, -0.1063494 ,\n",
       "        0.71884553,  1.27708112,  0.6665474 ,  0.6489707 ,  0.08223364,\n",
       "       -0.59530024,  0.8402098 , -0.34800633,  0.31743515, -1.31409316,\n",
       "        1.50046418, -2.23597049,  0.69168327, -1.11477397,  0.29592897,\n",
       "       -0.12506468, -0.12498823,  0.91843128,  0.33398924, -0.67332151,\n",
       "       -0.31981064,  0.60977717, -0.88251045,  0.41805617, -0.09196056,\n",
       "        1.11546806,  0.58768376, -1.4777305 ,  1.64582001, -0.44293982,\n",
       "       -0.72674104, -0.22844922,  2.74211371,  0.98771068,  0.54043377,\n",
       "       -1.62985155, -1.40909495,  1.35783599,  1.2381748 ,  0.53848498,\n",
       "       -0.16303289, -0.92469235, -0.4753287 , -0.24203016,  0.38805845,\n",
       "       -2.01060482,  1.1235076 ,  0.09571703,  0.17405188,  1.88161412,\n",
       "       -1.33764167, -0.91988662, -1.05227121, -0.5028993 , -1.6573394 ,\n",
       "        0.3749797 ,  0.25958985,  1.71754494, -0.8600091 ,  0.10810101,\n",
       "        1.73397512, -1.47675722,  0.80847634, -0.94419198, -0.31932844,\n",
       "       -0.32093927, -1.52692288, -0.14260829, -0.43135249,  0.31868118,\n",
       "       -0.20092268,  0.19909252, -0.81122413,  0.23837454, -1.58556702,\n",
       "        1.13328734, -0.78638311,  0.02785826, -1.530567  ,  0.90171234,\n",
       "       -2.81099855,  1.05687139,  0.28725315,  0.51899049,  1.3126033 ,\n",
       "        0.5824281 , -0.85097426, -2.58447976, -0.42938223, -0.84059318,\n",
       "        0.21817038, -0.38713467, -0.39309701, -0.22533256,  0.11898346,\n",
       "       -0.17965943, -0.9180118 ,  0.75615078,  0.26656353, -0.13122103,\n",
       "        1.44100967,  1.29167653,  1.06167518,  0.3062364 , -1.11698088,\n",
       "        2.34194794,  1.63661337, -0.15904863,  0.44997187, -0.29530245,\n",
       "       -0.77065233, -1.2677985 , -0.66469196, -0.12578221, -1.15470449,\n",
       "       -0.11294822, -1.0778156 ,  0.21411242, -0.47583954, -1.28880578,\n",
       "       -0.1257119 ,  0.21247534,  1.20918858, -2.26643074,  0.91339081,\n",
       "       -0.21550887, -1.24682543,  0.00575265,  0.04851171, -0.34401332,\n",
       "        1.13163493,  1.64644451,  1.31644472,  0.81720552,  0.13676836,\n",
       "        1.37762015, -0.15230973, -0.71986028, -0.18463948,  0.0526669 ,\n",
       "       -1.30812268, -0.82406562, -0.34408042,  0.32429355,  0.53077171,\n",
       "       -0.00508534,  0.36597472,  0.4214386 , -0.66802917, -2.12300401,\n",
       "        0.61614852,  1.17864893,  0.56029888, -0.87232075, -0.48694766,\n",
       "       -0.3907708 , -0.50039081,  0.92271117,  1.75704881, -1.28988161,\n",
       "        0.88730287, -0.19454886,  0.51689985, -0.31936304, -2.04862674,\n",
       "        1.23687945, -0.26953408, -0.81833736, -0.75127953, -0.85653481,\n",
       "        0.67042499,  0.1628959 , -1.18981368, -0.03541646,  0.94309495,\n",
       "        0.04750251,  0.5981932 , -1.82684627, -0.12553816,  0.70524913,\n",
       "        0.36547938,  1.56116599, -1.71180172,  0.29230035, -0.69617637,\n",
       "        0.3728349 , -0.46610739,  1.36669909,  0.8682768 ,  1.09490214,\n",
       "        0.54943252, -1.89700349,  0.42770143, -0.10162175,  0.22394128,\n",
       "       -0.34985236, -1.11307124, -0.05992353, -0.86754058,  0.63698332,\n",
       "        0.88685076,  0.70565538, -1.7786266 , -1.05115122,  0.74032659,\n",
       "        1.45934151, -2.76909876,  0.22576286, -0.42620204, -1.5384863 ,\n",
       "        0.72681866, -0.3734902 ,  2.52240614, -2.28407448, -1.89511701,\n",
       "        0.18319833, -0.42035732,  0.26855999, -0.23484573,  0.83466847,\n",
       "       -0.32708659,  0.88587405,  1.31466781, -0.93941191,  0.10071177,\n",
       "        2.43292085,  0.17198963, -0.619971  ,  0.29048927, -0.54146991,\n",
       "       -0.51519362, -0.21151265, -1.52253118, -1.55680171, -0.28672958,\n",
       "       -1.01698611,  1.56839961,  0.95744659, -0.36941633, -1.00850113,\n",
       "        0.60593946,  0.35775109,  1.07338708, -1.23364969,  0.04455541,\n",
       "       -0.23728156, -1.27792129,  1.9553049 ,  0.98166557, -0.84485242,\n",
       "        1.67747751, -0.16356468, -0.77215994, -0.43368613, -0.36142492,\n",
       "        0.57907317, -0.23732225, -1.49579951, -0.09958916, -2.16133947,\n",
       "        0.0771418 ,  1.24408915, -0.26919431,  0.38668034, -1.43474369,\n",
       "       -0.66558045, -0.09989113, -1.18881526, -0.28807381, -0.38413428,\n",
       "       -0.20503612,  1.45506797,  0.86063301, -0.84836694, -0.66640257,\n",
       "       -0.79267569, -0.98895647, -1.00490151, -0.92580449, -0.0498808 ,\n",
       "        0.26688188,  0.69809672, -0.77978042,  2.19994216, -0.50344191,\n",
       "        0.2027731 ,  0.08757244,  0.90464832,  0.73642437,  1.35049009,\n",
       "       -0.27562062, -0.32273469,  0.95633221, -1.3522399 ,  0.1866937 ,\n",
       "       -0.62363513, -1.72440701,  0.85677193,  0.72390964,  0.23515407,\n",
       "       -0.82026864, -1.68535597,  0.0763842 ,  0.82706686, -1.08404611,\n",
       "        0.90436325,  0.3393298 , -0.80135724, -0.60572376,  1.38067679,\n",
       "        0.25927899,  0.25400234,  0.63730548, -0.58335328,  1.68792419,\n",
       "       -0.29242147, -0.14853265,  0.70939471,  0.79108672,  1.25536077,\n",
       "        1.47502006, -0.16395008,  0.25177616,  0.02790709,  0.66778349,\n",
       "       -0.99263262, -0.2191455 ,  0.92440969, -0.17502786, -0.64852853,\n",
       "       -0.57200351,  1.31417235,  0.74264073,  0.35988256, -0.53318115,\n",
       "        0.54496694,  1.02151311,  1.745284  ,  0.10882443,  1.61013341,\n",
       "        0.96123037, -0.92583344,  0.68351459,  1.83539359, -0.67090408,\n",
       "       -0.46756592, -0.55033529, -1.33120922, -0.48858278,  1.29193883,\n",
       "        1.62133331,  0.09710457, -1.99169896,  0.81929479,  0.701704  ,\n",
       "        0.77725715, -1.22406463, -0.07358114,  0.79927817, -0.30222269,\n",
       "       -1.6833723 , -1.47816571,  1.65521172,  0.43025879,  0.37903117,\n",
       "        1.70169647, -0.66627656, -0.96926083,  0.41782518, -0.59938867,\n",
       "        1.20860361, -0.20722217, -0.38354637, -0.56503531,  1.09301659,\n",
       "        1.31166286, -1.29807703, -0.10856942,  0.61314972,  1.74590639,\n",
       "       -0.85793128, -0.2365451 , -1.30443265,  1.07578565,  0.4364992 ,\n",
       "       -0.74382651,  0.71085385, -0.5116977 ,  0.53724963,  0.38781554,\n",
       "        0.12641493,  1.04541952, -0.95237288, -0.22401655,  0.09841269,\n",
       "       -0.71126443, -0.48679536,  0.21749968, -0.90865375,  1.06256032,\n",
       "        1.23012793,  0.46508372,  0.49710735, -0.72541008, -0.22922017,\n",
       "        0.35211145,  0.59949263,  0.73351001,  1.28034133, -0.01679529,\n",
       "       -1.13776335, -1.86816535, -0.68071814,  0.40545891,  0.47479194,\n",
       "        0.79880879,  0.53045881, -0.94826877, -1.24125604, -0.10502937,\n",
       "        0.91918656, -1.01286628,  1.46686016, -0.07204534, -1.20444763,\n",
       "        1.04545032, -0.1482553 , -0.26363836, -1.5940242 , -0.01903324,\n",
       "       -0.46098932,  0.71641247, -1.07025383,  0.1400608 , -1.2390138 ,\n",
       "       -0.45445867, -2.18648895,  0.13925302, -0.16775641,  0.60062719,\n",
       "       -1.50519688, -0.15100036,  1.14507817,  1.18419009, -0.63776525,\n",
       "        0.90619879,  0.35761103,  0.9387177 ,  1.07332338,  1.48847873,\n",
       "        0.2427216 , -1.58731115, -0.29847976,  0.06328428, -1.23276681,\n",
       "       -0.17141921,  1.79874863, -0.34341471,  0.34298432, -0.56041556,\n",
       "        1.87524373, -2.21110784, -0.93255618, -0.74491505, -0.08487925,\n",
       "       -0.58415141, -1.35853791,  1.95573637, -1.26620314, -0.52228076,\n",
       "       -0.89797011,  0.41565663, -1.47425089,  0.73397583,  0.42819065,\n",
       "        0.90657212, -0.32506949, -0.52843486,  0.76845611,  0.75889072])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference.params['means']['w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21933907,  0.09154777, -0.17464079, -0.44870054, -0.83371875,\n",
       "        0.16700055,  0.48513607,  1.03219982, -0.65525364, -0.91894601,\n",
       "       -0.23075566,  0.32525144, -2.44780582, -0.9638856 , -0.09406932,\n",
       "       -0.99337411,  0.15840524, -1.02807847, -0.13885358])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.59002482,  0.37859894, -0.53644583, -0.6892309 , -0.99776871,\n",
       "        0.03972797,  0.4601806 ,  1.12462771, -0.41590812, -0.86359898,\n",
       "       -0.06527568,  0.5332345 , -2.35558899, -0.82688293,  0.0692633 ,\n",
       "       -1.160286  ,  0.04392596, -0.76753021, -0.1063494 ])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference.params['means']['w'][1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
